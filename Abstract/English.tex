\chapter*{Abstract}

% 4000 caract√®res

Although human-robot collaboration can be beneficial, most of today's robots work in spaces physically separated from humans, or their capabilities are severely limited in close proximity to humans. This work aims to bridge the gap between robotic capabilities and human expectations, fostering a new era of seamless and intuitive collaboration between humans and robots in shared environments to perform industrial, service or domestic tasks. More specifically, this manuscript presents a study of decision-making in the context of human-robot collaboration, particularly in the areas of task planning and simulating intelligent agents.

First, we discuss various fields and works related to human-robot collaboration to better understand my work's context. After an introduction to the HATP/EHDA task planner, I present my first contribution, which incorporates some concepts from the Theory Of Mind into task planning. Some models and algorithms are proposed and evaluated to better estimate and maintain human knowledge during collaboration, in order to better anticipate human behavior. As a result, we can identify when humans have false beliefs about a fact that is evaluated as relevant to the task. In this case, the robot can proactively inform the humans to correct the false information, or the robot can deliberately delay its actions so that the humans can see them. Our results show that this scheme effectively maintains human beliefs and solves a broader class of problems than HATP/EHDA, without communicating systematically.

My second contribution is a new approach to task planning producing a robot behavioral policy ensuring smooth collaboration where the human always has full decision latitude and the robot always conforms in parallel to these decisions. This approach is based on a concurrent and compliant joint action model we have designed. This model, in the form of an automaton, takes into account human uncontrollability and social cues. We also propose a new method of plan evaluation and selection based on the estimation of the human's internal preferences regarding the task. Empirical results show that this approach enables concurrent robot behavior that conforms to human's real-time decisions and preferences.

As another contribution validating the above approach, we implemented our proposed joint action model as an execution scheme into a dedicated simulator. Then, we conducted a user study where participants were invited to collaborate in several scenarios with a simulated robot following policies produced by our approach. In contrast with our approach, we used a baseline where the robot always imposes its decisions on the human. We showed through statistical analysis that our approach satisfies human preferences significantly more successfully than the baseline. Similarly, we have shown that our approach induces significantly more positive interaction, more adaptive and effective collaboration, and significantly more appropriate and accommodating robot decisions.

Finally, my last contributions concern simulating intelligent human agents. Such simulated agents endowed with decision-making capabilities can help to test, evaluate, and robustify interactive and collaborative robot systems. We propose a generic architecture to simulate an intelligent agent and present an implemented version for navigation use cases. An additional contribution capable of simulating several navigating agents is also presented.  
