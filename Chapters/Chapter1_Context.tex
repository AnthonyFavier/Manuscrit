\ifdefined\included
\else
\setcounter{chapter}{0}
\dominitoc
\faketableofcontents
\fi

\chapter{Human-Robot Collaboration Context}
\chaptermark{Human-Robot Collaboration Context}
\label{chap:1}
\minitoc

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Multidisciplinarity of Human-Robot Interaction}

\begin{figure}
    \center
    \includegraphics[width=\linewidth]{Chapter1/hri_multi.pdf}
    \caption{Multidisciplinarity of the Human-Robot Interaction field.}
    \label{fig:hri_multi}
\end{figure}

In \cite{bartneck_human_robot_2020}, the \acrfull{hri} is considered unique because of the interaction of humans with social robots, which is at the core of this multidisciplinary research field. These interactions usually include physically embodied robots, and their embodiment makes them inherently different from other computing technologies. Moreover, social robots are perceived as social actors bearing cultural meaning and strongly impacting contemporary and future societies. Saying that a robot is embodied does not mean it is simply a computer on legs or wheels. Instead, we must understand how to design that embodiment, both in terms of software and hardware, as it is commonplace in robotics, and in terms of its effects on people and the kinds of interactions they can have with such a robot.

Overall, HRI focuses on developing robots that can interact with people in various everyday environments. This opens up technical challenges resulting from the dynamics and complexities of humans and the social environment. This also opens up design challenges—related to robotic appearance, behavior, and sensing capabilities—to inspire and guide interaction. From a psychological perspective, HRI offers the unique opportunity to study human affect, cognition, and behavior when confronted with social agents other than humans. In this context, social robots can be research tools to study psychological mechanisms and theories.

As a result, by taking inspiration from Human-Human Interaction (HHI) and Human-Computer Interaction (HCI), HRI is an endeavor that brings together ideas from a wide range of disciplines such as Engineering, Computer Science, Robotics, Psychology, Sociology, and Design by taking inspiration from Human-Human and Human-Computer Interaction.
In the following, we discuss some related aspects and works of the mentioned disciplines by categorizing them in HHI, HCI, and HRI as depicted in figure~\ref{fig:hri_multi}.

\subsection{Human-Human Interaction}

Many works dealing with interacting with humans take inspiration from Human-Human Interaction (HHI), including research in sociology and psychology. HHI refers to the communication and collaboration between two or more individuals, where humans engage in various forms of social, cognitive, and emotional exchanges. Such interaction can occur through verbal and non-verbal communication, such as speech, gestures, facial expressions, and body language.   

\textbf{TODO: detail more each aspect with words}

Communication theories, both verbal or not: Albert Meharbian's 7-38-55 rule \cite{mehrabian1967decoding}, and the Grice's four maxims of conversation called the Gricean maxims: quantity, quality, relation, and manner. These four maxims describe specific rational principles observed by people who follow the cooperative principle in pursuit of effective communication \cite{grice1975logic}.
\cite{smith_designing_1998}, \cite{cherry_human_nodate})

Joint Action theories, including collaboration and teamwork (\cite{cohen_teamwork_1991,cohen_team_1970,levesque_acting_1990})

Social psychology (Stanley Milgram, Philip Zimbardo, and Solomon Asch)

conflict resolution and negotiation (Roger Fisher and William Ury)

emotional intelligence (Daniel Goleman)

cross-cultural communication.


We must first understand how humans interact with each other before making robots able to interact correctly with humans. Nevertheless, mimicking humans perfectly is questionable since robots fundamentally differ from humans. Robots are created by humans to be helped and assisted. Thus, HHI should inspire robot design, but additional research is mandatory to determine how to create appropriate interactive and collaborative robots.

\subsection{Human-Computer Interaction}

A first step of artificial interaction and collaboration is the field of Human-Computer Interaction. Human-Computer Interaction (HCI) is the field of study that focuses on optimizing how users and computers interact by designing interactive computer interfaces that satisfy users' needs. It is a multidisciplinary subject covering computer science, behavioral sciences, cognitive science, ergonomics, psychology, and design principles.
Today, HCI focuses on designing, implementing, and evaluating interactive interfaces that enhance user experience using computing devices. This includes user interface design, user-centered design, and user experience design. 

This field is made up of four key components. 
The User along with their needs, goals, interaction patterns, cognitive capabilities, emotions, and experiences.
The Goal-Oriented Task which is the objective or goal the user has in mind.
The Interface is about the overall user interaction experience through senses such as touch, click, gesture, voice, display size, colors.
The Context must be taken into account because it influences the interaction. 

To produce easy to interact with robots, the study of HCI is relevant and also serves as an inspiration to design intuitive, user-friendly interactive robots.

\subsection{Human-Robot Interaction}

% \textbf{TODO: check for consistency and redundancy with intro of upper HRI section. Add computational HRI refs}

% \textbf{Include social interactions, emotional support, story telling. Other works than collaboration}

Human-Robot Interaction (HRI) is a field of study that explores the design, development, and evaluation of robots that interact with humans in various settings. HRI aims to create robots that can effectively and seamlessly collaborate with humans in domestic environments, workplaces, or other contexts. 
HRI can be categorized in several domains, not necessarily exclusive. Here are some examples:

\uline{Social robotics} focuses on social interactions with humans and, thus, explores how robots can understand and respond to human emotions, social cues, and communication styles.
A significant amount of work is dedicated to HRI in Healthcare to assist patients, especially the elderly and children with conditions. Those works are also usually linked to emotion-aware robotics focused on recognizing and responding to human emotions using affective computing techniques. A common application is storytelling for children to convey ideas, feelings, or culture. 

\uline{Human-Centered Robotics} emphasizes the importance of considering human needs and preferences. This subfield often involves user studies to ensure and identify if and how robots are user-friendly and can seamlessly integrate into human environments.

\uline{Robot Ethics} is another central subfield focused on considerations such as privacy, safety, responsibility/accountability, and the impact of robots on society.

\uline{Explainable AI and transparency} are a growing interest in making decision-making processes more understandable to humans, and thus, help robots be legible, predictable, and acceptable.

\uline{Computational HRI}, as described in~\cite{thomaz_computational_2016}, is the subset of HRI concerned explicitly with the algorithms, techniques, models, and frameworks necessary to build robotic systems that engage in social interactions with humans. This thesis is part of this category because it is focused on developing task-planning algorithms and models relevant to a collaborative robot. 

\uline{Human-Robot Collaboration} or \uline{Collaborative Robotics} focuses on developing robots that work alongside humans in shared workspaces, usually as a team. HRC is the main topic of my thesis and is a vast subject worth delving into. Hence, the following section is dedicated to providing more details about HRC.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Human-Robot Collaboration}

Human-Robot Collaboration (HRC) refers to the synergy and cooperation between humans and robots in shared environments to achieve common goals. In HRC, humans and robots work together, often leveraging their complementary strengths to enhance overall performance and efficiency. According to human desires, the robot can also act in a way that eases and facilitates the human part of the task. This collaborative approach involves close interaction, communication, and coordination between human and robotic agents.

\subsection{Inspirations \& Theories informing HRC}

This interdisciplinary field takes inspiration from various theories and fields as introduced earlier. Nevertheless, three main inspirations can be highlighted:

\subsubsection*{Belief Desire Intention Model:} The belief-desire-intention (BDI) model was originally developed by Michael Bratman~\cite{Bratman1987_BRAIPA}. This model is used in intelligent agents research to describe and model intelligent agents. Straightforwardly, the BDI model is characterized by the implementation of the three notions appearing in its name, i.e., an agent's beliefs (knowledge of the work in the perspective of the agent), desires (objective or goal to accomplish), and intentions (the planned course of actions to achieve the agent's desire). 

\subsubsection*{Shared Cooperative Activity:} Shared cooperative Activity defines prerequisites for an activity to be considered shared and cooperative. The main ones are mutual responsiveness, commitment to the joint activity, and commitment to mutual support. A good example to clarify these prerequisites is a scenario where agents move a table together. Mutual responsiveness ensures that the agents' movements are synchronized. The commitment to the joint activity reassures each agent that the others will not drop their side and quit the joint activity. Finally, the commitment to mutual support deals with possible breakdowns due to one agent's inability to perform part of the plan.  

\subsubsection*{Joint Intention \& Action Theory:} 
Joint Intention Theory proposes that for joint action to emerge, team members must communicate to maintain a set of shared beliefs and to coordinate their actions toward the shared plan~\cite{cohen_teamwork_1991}. In collaborative work, agents should be able to count on the commitment of other members. Therefore, each agent should inform the others when they conclude that a goal is achievable, impossible, or irrelevant~\cite{hoffman2004collaboration}.

\subsection{Key Aspects}

% More concretely, some key aspects of a seamless collaboration are listed and commented on below to better picture what the theories above involve in practice. 

In order to better picture the implications of the above theories, some key aspects of a seamless collaboration are listed and commented on below. This list is not exhaustive, but it highlights some skills that humans naturally exhibit and that a robot must be endowed with to collaborate with them. 

\textbf{Specialization of Roles:} There are several human-robot relationships, including supervisor-subordinate, partner-partner, teacher-learner, and leader-follower. These roles can be predefined and fixed during the whole collaboration. The role distribution can also be flexible using weighting functions that allow a continuous change between the roles to adapt to every context and situation.

\textbf{Establishing shared goal(s):} Through direct discussion or inference, agents must determine the shared goals they are trying to achieve. However, a shared goal isn't always necessary and can be established in the middle of a task execution either by the human or the robot.

\textbf{Allocation of subtasks:} After deciding how to achieve their goals, agents must determine what actions and subtasks will be done by each agent and how to coordinate each other. This can either be done explicitly before starting the task or be reactively done on the fly.

\textbf{Progression tracking:} Agents must be able to track progress toward their goals. That is, they must be able to determine what has been achieved, by whom, and what remains to be done. 

\textbf{Communication:} Any collaboration requires communication, verbal or not. Most of the mentioned aspects can or must involve communication. However, it is essential to identify what and how to communicate during the collaboration. Communicating too much can be annoying, while not enough can induce confusion and harm collaboration.

\textbf{Adaption and learning:} On a short-term scale, agents must adapt to each other and the environment. In the longer term, agents must also learn from other partners and the acquired experience.

\textbf{Ergonomics:} It should be intuitive to collaborate and communicate with the robot. This aspect must be taken into account when designing both the hardware and the software of the robot. Ergonomics is a central aspect of Human-Compute Interaction. Thus, many works from this field can be used in our context or serve as inspiration.

\textbf{Explainability:} This aspect is important for seamless collaboration as the human should be able to understand what the robot is doing and why. This topic is getting more and more attention and is often referred to as Explainable AI. This is especially relevant to counter the \textit{black box} tendency of machine learning where it's impossible to explain a specific decision. Being explainable often enhances predictability, which is also essential for a collaborative robot.

\subsection{Architectures \& Complete systems}

It is important to remember that since a collaborative robot is issued from an interdisciplinary field, its different functionalities and capabilities are usually separated into several dedicated components. These components interact and communicate with each other, forming a complete architecture. This architecture covers all aspects relevant to exhibiting the robot's behavior, from sensory perception to physical motions, including reasoning processes. 
Despite developing distinct robotic components, the robot must be considered a whole. Each component cannot be studied entirely independently of other aspects of the complete system.  

As a result, some works are dedicated to designing robotic architectures, especially cognitive architectures, which are the most promising ones for designing collaboration robots. 

Example of cognitive architecture
[cite SOAR Laird et al, CORTEX Bustos et al, ORO/SHARY/SPARK.. Lemaignan, perspective-aware Lemaignan]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models for interaction}

\textbf{For now, mostly from Buisan thesis}

It has been shown previously that a robotic agent interacting with a human needs to coordinate its actions with them [cite?]. Moreover, joint action theory exhibits that humans interacting together represent the task as a whole, and plan not only for their actions but also for the actions of other agents. Thus, we think that for a human to perform the most efficient and satisfactory joint task with a robot, this robot must explicitly model human actions and plan not only for its actions but also for the human ones. This is why we present in this section some notations to clarify the different models used in this thesis, and then we present in more details how to model tasks.

\subsection{Human and Robot agents}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{Chapter1/chakraborti_notations.jpg}
    \caption{Agent models from Chakraborti \textit{et al.} notations.}
    \label{fig:chakraborti_notations}
\end{figure}

\textbf{TODO: details whats inside of the models}

Chakraborti \textit{et al.} introduced notations to differentiate between the models used in this thesis in their work~\cite{ChakrabortiBTZS15}, also used in Buisan's thesis~\cite{thesisBuisan21}. These notations summarize and differentiate elegantly the different models manipulated in the HRI/HRC field. These notations are depicted in figure~\ref{fig:chakraborti_notations}. At the bottom are depicted the human agent (on the left) and the robot agent (on the right). When solving a task alone, the robot uses its own model referred to as $\mathcal{M}^R$ and this is considered as Classical Planning. 
Then, $\mathcal{M}^H_r$ is an estimation by the robot of the model of the human. Finally, $\tilde{\mathcal{M}}^R_h$ is an estimation of the robot model the human has. 

It is important to keep in mind that when discussing a task planner it is considered as part of the robot. Thus, $\mathcal{M}^R$ is considered as the ground truth for the robot. As a consequence, if there is a belief divergence between $\mathcal{M}^H_r$ and $\mathcal{M}^R$, we always consider that $\mathcal{M}^R$ is the truth, otherwise, it would make no sense to keep this information in $\mathcal{M}^R$ while having access to the one in $\mathcal{M}^H_r$.

\subsection{Task modeling}

A common way of representing human activity (MrH ) and interaction with computers at a high abstraction level is by using task models. The hierarchical structure of human activity was first exploited by Annett and Duncan [Annett 1967]. They state that tasks can be described at several levels of abstraction until a certain criterion is met. Each task can thus be refined into subtasks detailing the procedure followed by the human to achieve the higher level task. Task modeling has then evolved to introduce interaction with systems, produced and needed information, potential errors and a wide variety of operator specifying how tasks interact with each other during their execution. Task models are now commonly used in user-centered and user-interface design processes. Most advanced notations include ConcurTaskTrees [Paternò 2004] and HAMSTERS [Martinie 2019]. These models are used to design or evaluate interactive systems. They allow the designer to better understand the user task or to study the user workflow using their system. However, these models contain too little information for a system to be able to reason and make decisions on them (either in planning or acting).


\subsection{Hierarchical models}

In classical planning, each action of an agent is atomic and needs some conditions to hold in the environment to be executed, then it changes the environment when applied. The planning process has then to find the right sequence of actions, being applicable one after the other to change the environment to reach a certain goal state. 
However, it has been shown (cite?) that humans tend to plan their actions differently. Indeed, we usually work on a more abstract level and tend to decompose tasks hierarchically into small tasks until reaching the action level. In practice, using Hierarchical Task Networks (HTNs) allow the domin designer to help the plan search by inserting expert knowledge via a hierarchy linking the actions [erol 1996]. A task network consists in tasks organized in a fully or partially ordered manner, and each task can be either abstract or primitive. Primitive tasks are elementary tasks that can be achieved by performing one associated action. On the other hand, abstract tasks are tasks that first need to be decomposed into other subtasks, ``more primitive". The goal of the planner is not to find the sequence of actions to reach a goal, but rather to select recursively for each task the right decomposition ending (if possible) with a network of actions applicable from the initial state. Such a process is named by Ghallab, Nau and Traverso as planning with refinement methods [Ghallab 2016]. This planning hierarchy not only allows the domain designer to guide the search by inserting some expertise into the model, but also to enhance explainability as the decompositions often offer a semantic to their subtasks the why can usually be answered by going up in the hierarchy, while the how is answered by going down. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Task Planning}

\subsection{Classical Planning}

As put by Ghallab, Nau and Traverso, “the purpose of planning is to synthesize an organized set of actions to carry out some activity” [Ghallab 2016]. 
Classical planning is a type of planning that assume deterministic and fully observable environments. It involves representing the world as a set of states and actions, with plans derived through state space search algorithms. Actions have preconditions and effects, and planning problems entail finding a sequence of actions transforming an initial state into a goal state. Classical planning algorithms, including STRIPS, Graphplan, and Fast Downward, utilize heuristics to guide the search efficiently. While well-suited for domains with clear and deterministic dynamics, classical planning may face challenges in handling uncertainty or partial observability, leading to the development of alternative planning approaches for such scenarios.

\subsection{Planning for HRC}

Classical planning has been vastly studied and can now solve efficiently various problems. Yet, the intricate nature of HRC scenarios demands sophisticated task-planning methodologies capable of adapting to dynamic environments, understanding human intent, and promoting a fluent exchange of information. Hence, several subfields of task-planning have emerged and are used in HRC. Here are a few examples:

\begin{itemize}
    \item \textbf{Hierarchical Task Planning} is a technique that organizes tasks in a hierarchical structure like presented in the previous section, allowing for the representation of complex tasks at various abstraction levels. This approach enhances modularity, flexibility and explainability in task planning, accommodating intricate collaborative scenarios.
    
    \item \textbf{Mixed-Initiative Planning} leverages the strengths of both humans and robots by allowing for a dynamic allocation of decision-making authority. This technique promotes collaborative decision-making, enabling the system to adapt to the expertise and preferences of each agent involved in the collaborative task.
    
    \item \textbf{Human-Centric Task Planning} focuses on incorporating human factors into the planning process. This involves understanding human capabilities, preferences, and cognitive load to optimize task plans that align with the natural workflows and expectations of human collaborators.
    
    \item \textbf{Learning-Based Task Planning} has emerged thanks to advancements in machine learning as a frontier in adapting to evolving environments. This technique involves training models to understand patterns in human behavior, enabling the robot to learn and adapt its task planning strategies over time. Such techniques can also be used to predict human behavior and adapt the robot's actions consequently.
    
    \item \textbf{Probabilistic Task Planning} integrates uncertainty into the planning process, acknowledging the inherent unpredictability of human behavior and environmental factors. By incorporating probabilistic models, this technique enhances the robustness of task plans in dynamic and uncertain collaborative settings.
\end{itemize}

Overall, \textbf{Human-Aware Task Planning} is the process of considering the presence and behavior of humans in the planning and execution of robot tasks. It involves taking into account cues from the shared environment and the dynamics of human-robot interaction. The goal is to generate robot policies that are adaptable, robust, and efficient in crowded and dynamic environments. This field includes having an explicit shared task or common goal between the human and the robot, implying that the two agents will collaborate to reach the goal. It also includes not having an established shared goal, and thus, is closer to what I would call an interaction instead of a collaboration. Yet, both problems are interesting and must be addressed, with a unified approach or not. 
The approaches presented in this thesis are in between the first three subfields listed above. 

\subsection{Utilities of planning}

\textbf{TODO: to develop}

\begin{itemize}
    \item Planning techniques can be generalized.
    \item Mixed with motion planning: symbolic and geometric reasoning
    \item In dialogue
    \item other context?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Human-Aware Navigation}

\textbf{TODO: transition with task planning}

In my work I studied the decision-making challenge mostly in the field of task-planning. 
Nevertheless, I also worked on decision-making processes for navigation, more precisely, on how to simulate a navigating interactive human agent endowed with decisional capabilities to challenge robotic navigation systems. Hence, to better understand this contribution, this section provides some context on robot navigation, especially on state-of-the-art techniques and existing benchmarking tools.

As stated in \cite{thesisBuisan21}, robot navigation aims to make the robot base (the whole robot) move from one place to another while avoiding static and moving obstacles. However, other constraints must be added when the robot has to move in an environment where humans are evolving. 
Humans should not just be avoided as other moving obstacles, and their psychological and mental state must be taken into account. Hence, the robot should neither move threateningly, block the humans, nor induce drastic changes in their motion. Taking all these aspects into account is what is called human-aware robot navigation.

\subsection{Robot Navigation techniques}

State-of-the-art techniques for robot navigation involve two kinds of motion planners: a global and a local planner. The global planner is in charge of finding the best overall trajectory leading the robot to its goal, producing a global plan. This planner usually only takes into account static obstacles described by a given map of the environment. Then, the local planner is in charge of producing velocity commands sent to the motor controllers to follow the produced global plan. To produce the velocity commands the local planner may produce a local plan with only a few seconds of time horizon that follows the global plan while taking into account obstacles detected in real-time by the robot sensors, including moving obstacles. This way the robot should reach its goal while being reactive to moving obstacles. 

Recent techniques also involve learning methods. \textbf{TODO: add citations and description}

However, how explained above, such approaches are not sufficient in human-populated environments. Humans must be detected and treated differently during the motion planning process. Human-aware approaches detect and track nearby humans and try to estimate their trajectory to plan the robot one accordingly. This is achieved in works like [cite CoHAN] where the human trajectory is estimated using goal recognition processes and elastic bands methods. Then, the robot's motion is planned using also elastic band methods that are tuned to take into account the robot's goal, the estimated human trajectory and other social norms.   

\subsection{Benchmarking tools and metrics}

Where it is easy to benchmark robot navigation on objective metrics like the time to reach a goal, the distance traveled and the number of collisions [cite BARN Perille], it is more challenging to benchmark their human-aware properties.
First, there is no consensus on the metrics to use to evaluate the human-aware properties of a navigation system. State-of-the-art metrics involve proxemics [cite]. Yet, other metrics can be relevant such as the deviation imposed to the human motion, and the feeling of threat produced.
Also, it is challenging to find a usable system that will effectively challenge a HAN system. 
Common approaches involve reactive-only techniques such as social force models \textbf{TODO: cite + figure?}. Such reactive models are easy to use and efficient for crowd simulations, but in intricate scenarios involving some decision-making they can perform very poorly. Thus, there was a lack of intelligent simulated agents to challenge effectively HAN system.
I started to work on this aspect in 2020. Now, a few recent work also propose to simulate human agent endowed with some reasoning processes but I didn't find the time to properly compare my contribution with them. Yet, this shows that this is a subject of interest and a few a such work can be mentioned here. Some related works will be discussed in Chapter~\ref{chap:6}.
