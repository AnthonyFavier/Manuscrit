\chapter{Conclusions}
% \addstarredchapter{Conclusions} 
\markboth{Conclusions}{}

% The final remarks, lessons learnt, and future perspectives are discussed in the Conclusions chapter. The supportive work presented in Appendix A shows how an intelligent human agent is developed for the case of HAN. Further, different methodologies employed to simulate human agents for testing our HAN system are also presented. Throughout this thesis, whenever we refer to robot navigation, it is always a mobile robot with either differential or omnidirectional drive navigating on a 2D plane.

%%%%%Update this later%%%%%%%%%%%%%

In this thesis, we have explored the problem of mobile robot navigation in human environments, generally called human-aware navigation (HAN). We have presented detailed literature on how the field evolved and some existing challenges. Numerous solutions were proposed for HAN in motion planning literature by modelling humans as special obstacles. However, we believe that HAN is essentially an interaction between humans and robots. Therefore, it should satisfy the principles of HRI. In this thesis, we have put together these ideas and proposed a HAN that assesses a situation to take appropriate action. Although situation assessment and behaviour shifting have already been explored in HAN, they were mostly used on top of motion planning systems. Unlike the previous approaches, we have introduced situation assessment at the level of trajectory planning to shift between different modes of planning while the robot navigates to the goal. As this low-level mode shifting was combined with proactive planning, the robot can deal with complex situations in an efficient manner before it is too late. Proactive planning itself has some very interesting features, like quick plan adaptations and early intention shows, but there could be some very complicated situations where proactive planning may not be sufficient. The situation assessment based modality shifting is useful in such places.

We have presented three versions of our HAN system, starting with the idea of introducing modality switching inside the local trajectory planner. There were several improvements over the previous version of HATEB, and these improvements, combined with the mode switching scheme, are some of the major contributions of this thesis. Qualitative and quantitative results have shown the advantages of such an approach in various settings. We then moved on to propose a Human-Aware Navigation Stack called CoHAN with many changes to scale the system to multiple humans and to address different types of humans. CoHAN can be seen as a complete navigation stack for HAN with different costmap layers, human path prediction mechanisms, and several modes of planning that can solve most of the intricate human-robot navigation scenarios. The early intention show and the Backoff-recovery act as implicit communication mechanisms to tell the human what the robot is going to do. In the future, we plan to integrate more explicit communication through head orientation and probably voice. Various kinds of human states combined with the situation assessment can address more complicated scenarios, and to ease this, we plan to modularize the future version of CoHAN with detailed documentation. CoHAN has been tested on simulated crowds and has already shown some promising results. However, we believe that crowd navigation could be more complex, and we need more modalities and mechanisms to handle crowds efficiently. We have already presented some ideas we plan to integrate into the future version, and we expect to add more.

Apart from addressing multi-context navigation, we have also focused on one key aspect throughout the development of our HAN system, legibility. We have introduced some new human-aware constraints to make the robot's motion more legible to the human. To show the intention of the robot early, we have proposed TTC, TTCplus and Relative Velocity constraints. The Relative Velocity constraint also addresses the issue of directionality in the crossing or close-to-human navigation scenarios. We have introduced the Visibility constraint to avoid any surprises or shocks to a human when the robot overtakes the human. One more attempt to improve legibility was done through 'invisible humans’. We have introduced this concept into HAN to make sure that the robot is aware not only of the humans it is seeing but also of the environment and the places humans might emerge. We believe that this makes the system more complete and ready to face any kind of environment without behaving erratically or freezing. The `invisible humans’ concept has also made it possible to identify different places on the map through geometric reasoning and introduce different modalities of planning depending on the situation. Further, the algorithm was rigorously tested and showed satisfying performance in some very complex maps. The final version of CoHAN integrated with the `invisible humans’ has been shown to perform better and move smoothly without having any freezing robot problems. 

One of the open challenges in HAN is its evaluation, and the currently existing metrics do not do justice while the robot is navigating very dense crowds or confined spaces. As most of them are based on proxemic zones that are variable from place to place and the experiences of the person, it makes it more difficult to generalise the metrics to all cases of HAN. Therefore, we proposed some new metrics of evaluation using velocities and visibility along with distance. The velocity based metrics, $cost_{danger}$ and $cost_{passby}$, aim to measure the feeling of threat and discomfort caused to the human depending on the direction and speed of the robot's heading. Since these metrics combine distance and velocity, they can explain intricate settings better than proxemic zone violations. The first one of the vision based metrics,$cost_{visibility}$, was designed to measure how well a robot can approach a human from behind. The other metrics, $cost_{surprise}$ and $cost_{react}$, aim to measure the surprise(or shock) and risk caused when a robot appears in front of a human suddenly. The comparison between a standard navigation planner and a HAN planner showed how these metrics evaluate the `human awareness' of the system.

%%%%%%%%%%Talk about the magic numbers %%%%%%%%%%%

Human-aware navigation is not a very simple problem to address, and it taught us some valuable lessons. The developed systems are hard to validate in real-world settings. The experiments could be tedious, not easily reproducible and can be limited. Not every robot is the same. The structure of the robot matters to humans in the environment. Their behaviour towards the robot changes as the shapes and designs of the robot change. Humanoid structures are accepted better than simple mobile bases, even with the same algorithm. One of the important aspects while developing a HAN system is to have a good simulator that can generate realistic human behaviours. To this date, there is no perfect human simulator. The HAN research community has been using crowd simulators or directly testing with real humans. Crowd simulators are mostly reactive and are not realistic. On the other hand, tests with real humans are tedious and require a lot of resources and time. Although there is rapid growth in this aspect, the community is still waiting for a reliable robot simulator that can simulate rational human agents. We require more user studies to understand the intricacies of human-robot navigation. This is the right moment to invest more time into these studies, as drones and autonomous vehicles have also entered the field. The robotics community seems to have realised this, and now, there are special sessions dedicated to human-aware motion planning and human-aware navigation. The number of studies has already increased, and many researchers in motion planning are coming together to address this complicated yet interesting problem of robotics that can eventually lead to a society where humans and robots coexist.

There are already many immediate future perspectives for HAN. As autonomous vehicles have already hit the roads, it is time to make them behave socially by making them aware of humans and their intentions. An autonomous vehicle not only needs to be safe but also needs to obey certain rules and untold norms followed in society. HAN studies this problem exactly. Drones have become very affordable, and some companies are planning on using them for deliveries, while others are planning to use them as helpers in construction. All these applications require drones to navigate around humans and communicate with them. HAN in drones needs to study these in more detail and come up with better navigation systems for drones. Apart from guiding people in public places, some other applications of HAN  lie within warehouses where they need to work or deliver goods to different locations. These environments are more structured, and solving HAN in such places is much easier. HAN has been and will always be used in the sector of service robotics. Be it a robotic companion, a robotic wheelchair or robots in hospitals delivering medicines or equipment the HAN system faces dynamically changing environments where safety is one of the main concerns. A multi-context tunable navigation system could address most of these scenarios by choosing a set of parameters suitable for the setting.

