\chapter*{Introduction}
\addstarredchapter{Introduction}
\markboth{Introduction}{Introduction}




\minitoc

\acrfull{hrc} is a growing field in robotics and \acrfull{ai} research that aims to enable safe and effective teamwork between humans and robots.
This field concerns fully autonomous robots. Hence, it excludes exoskeletons or teleoperated robots such as surgery manipulators or remotely operated (aerial) vehicles. 

The work presented is assumed to be in the Joint Action context, which is described in \cite{sebanz_joint_2006} as ``any form of social interaction whereby two or more individuals coordinate their actions in space and time to bring about a change in the environment''. Various relationships can exist between humans and robots, e.g., collaborators, companions, guides, tutors, or social interaction partners. In all these cases, we think the robot should help and facilitate the human in terms of physical effort, mental workload, and even emotional state.

Industrial robots are already popular in factories because they are fast, accurate, reliable, and never get tired, which makes them ideal for repetitive factory tasks. 
However, such robots are usually in dedicated areas where humans cannot enter for safety reasons. 
Hence, it is still an open challenge to endow robots with enough reliable reasoning capabilities and compliant motion control to allow efficient and trusted direct collaboration between humans and robots. 

Moreover, \acrshort{hrc} can also occur in various contexts that must be considered, ranging from co-worker robots in factories to householder robots for our everyday lives and including service robots in public places like restaurants and shops.

Focused on the decisional aspect of \acrshort{hrc}, this work aims to design autonomous robots able to make explainable, acceptable, and efficient decisions to collaborate with humans. 

\acrfull{hrc} is a multidisciplinary field that opens several technical challenges to address. The ideal collaborative robot should be the aggregation of solutions for each of the challenges listed below:

\begin{itemize}
    \item \textbf{Navigation}: The robot should be able to acceptably and efficiently move in a human-populated environment. This implies being mechanically designed for it, anticipating and planning correct trajectories, and being able to adapt and follow these trajectories in real time. The robot should not move threateningly and should account for humans.

    \item \textbf{Manipulation}: The robot should be able to manipulate objects to interact with its environment. Hence, the robot should have an actuator like an arm and a gripper and should be able to exhibit motions that are efficient and safe to nearby humans.

    \item \textbf{Communication}: To achieve congruent interaction and collaboration, collaborative agents must communicate. This implies that the robot should be able to communicate information to the human and understand the one received from the latter. These communications can be verbal or non-verbal.

    \item \textbf{Perception}: It is mandatory for the robot to have a reliable perception scheme to know the position of near objects, obstacles, and humans. First, relevant sensors must be used and placed on the robot or in the environment itself. After reasoning on the sensory data, relevant facts about the robot's environment, such as objects' positions, spatial relations, reachable objects, human knowledge, intentions, or the state of the current goal, must be extracted. 
    
    \item \uline{\textbf{Decision-making}}: This aspect is the focus of my work and implies that the robot should be able to make relevant decisions to be collaborative, that is, planning its actions to solve a collaborative task. It also implies being able to supervise the task execution and make online decisions to adapt to uncertainties in real time, which includes human actions and commands. 

\end{itemize}
    
\mysection{Contributions and manuscript organization}

My work addressed the \textbf{decision-making} aspect of \acrshort{hrc} and led to three main contributions.
I began by participating in the development of a novel human-aware task planner called HATP/EHDA~\cite{buisan_hatpehda_icra}. This approach considers two distinct agent models: an uncontrollable one to estimate the human's behavior and a controllable one to plan the robot's actions accordingly. The agent models include distinct beliefs, agendas, and action models. As a result, the planner can anticipate and even elicit human decisions and actions, but it never compels them. For these reasons, we believe this approach is promising to address \acrshort{hrc}, and I built two of my main contributions upon this approach.

My first contribution is to propose some models and algorithms of the Theory of Mind and to integrate them into the deliberation process of HATP/EHDA. Despite considering distinct beliefs, they were only updated according to the description of the action effect provided in the estimated human action model. This means, for instance, that modeling the human observing and learning a new fact by entering a room had to be manually scripted in the `move' action description. With this contribution, we propose that an agent can learn by observing their surroundings or an action execution. Additionally, we propose a way to detect false human beliefs during the planning process, which may be detrimental to the task. Eventually, these relevant belief divergences are fixed by planning minimal verbal robot communication or delaying robot action that humans will initially not observe.

My second contribution brings planning and execution closer by addressing the turn-taking assumption of HATP/EHDA and exploring parallel executions. We formulated a step-based model of compliant and concurrent joint action. This model describes how the two agents should coordinate as well as four possible online human decisions about the execution: (1) the human decides to be passive and let the robot act alone, (2) the human acts alone and the robot is passive, (3) the human starts acting then the robot adapts and acts in parallel, and finally (4) the human deliberately let the robot decide and start acting before complying with it. This model guides the exploration of our proposed new human-aware task planning approach. After exploring all relevant courses of action, the robot's behavioral policy is extracted using a plan evaluation based on estimations of human preferences. Eventually, by following the produced policy, the robot can comply concurrently with any human online decisions and aims to satisfy human preferences, which can be updated online.

My last contribution is distinguishable from the previous two because it addresses navigation decision-making instead of task planning. Indeed, I designed and implemented two systems simulating interactive social navigating agents endowed with decision-making processes. Additionally, these systems include evaluation processes to record data, compute metrics, and plot navigation performances. These systems generate challenging situations that permit challenging, debugging, and evaluating robot navigation schemes in intricate human-populated scenarios. The first system, \acrfull{inhus}, simulates a single human agent endowed with complex reasoning processes. The second system, \acrfull{imhus}, simulates several agents with social group behaviors but with less individual reasoning capabilities. 

These contributions are detailed in the rest of this manuscript. The latter is structured as follows.

\textbf{TODO: update structure description with less details since contributions are already described above.}

Chapter~\ref{chap:1} provides more details about the context of my PhD by discussing related fields and works of \acrshort{hrc}. This chapter eventually highlights the gap in the literature that motivates my PhD work.

The rest of the manuscript is divided into two parts. Part~\ref{part:1} gathers all my work concerning task planning for \acrshort{hrc}. It represents a major portion of my PhD work and includes the chapters~\ref{chap:2}, \ref{chap:3}, \ref{chap:4}, \ref{chap:5}, and \ref{chap:6}. Part~\ref{part:2} concerns decision-making in navigation and how to simulate interactive social navigating agents. This part includes the two last chapters: \ref{chap:7} and \ref{chap:8}.

Part~\ref{part:1} begins with Chapter~\ref{chap:2}, which presents the HATP/EHDA task planner. This planner has been the keystone of most of my work. Hence, the reader should understand the motivation and methods of this task planner.

Chapter~\ref{chap:3} describes my first main contribution, proposing models and algorithms to incorporate Theory of Mind concepts in \acrshort{hrc} task-planning. An empirical evaluation is provided and discussed, demonstrating how this contribution solves a broader class of problems than HATP/EHDA without systematic communication.

Chapter~\ref{chap:4} presents my second main contribution, proposing a new human-aware task planning approach based on a step-based compliant and concurrent joint action model. The approach's description is supported by empirical results proving its effectiveness in terms of the latitude of choice given to the human and the satisfaction of their internal preferences. We further validated this by developing an interactive simulator used for a user study, described in the following chapters.

Chapter~\ref{chap:5} is a technical description of an interactive simulator I developed to execute the robot policy generated by the approach described in the previous chapter. This simulator proposes an execution scheme based on the model of execution to run and supervise the robot policy in a 3D simulator. It also allows a human operator to perform actions through intuitive mouse control. Hence, this simulator offers a way to collaborate with a robot following the approach we designed, and it will be used in the next chapter to evaluate the approach.    

Chapter~\ref{chap:6} presents a user study validating the approach proposed in Chapter~\ref{chap:4} using the simulator described in Chapter~\ref{chap:5}. For this purpose, several scenarios have been designed using a BlocksWorld task, and human participants were asked to collaborate with the simulated robot to evaluate its behavior. We compared our approach with a baseline behavior where the robot always imposes its decisions on the human. 

Part~\ref{part:2} begins with Chapter~\ref{chap:7}.
This chapter describes the InHuS system, addressing decision-making in navigation and challenging robot navigation schemes. This chapter also compares two robot navigation systems using InHuS, proving that our approach effectively challenges robot schemes and allows measuring and comparing human-aware navigation properties.


Chapter~\ref{chap:8} presents IMHuS, which complements the previous system to choreograph several agents with group movements and social behaviors. This system has been qualitatively evaluated in an elevator scenario.


Eventually, general conclusions regarding my overall PhD work are shared. Additional materials are provided in the appendix.  

\mysection{List of Publications}

\subsubsection*{As main author}
\begin{itemize}

    \item Anthony Favier, Phani-Teja Singamaneni, Rachid Alami. Simulating Intelligent Human Agents for Intricate Social Robot Navigation. Social Robot Navigation workshop - Robotics: Science and Systems (RSS'21), Jul 2021, Washington, United States. 
    \item Anthony Favier, Phani-Teja Singamaneni, Rachid Alami. An Intelligent Human Avatar to Debug and Challenge Human-aware Robot Navigation Systems. Late Breaking Report - 2022 ACM/IEEE International Conference on Human-Robot Interaction (HRI'22), Mar 2022, Sapporo, Japan. 
    \item Anthony Favier, Shashank Shekhar, Rachid Alami. Robust Planning for Human-Robot Joint Tasks with Explicit Reasoning on Human Mental State. AI-HRI Symposium at AAAI Fall Symposium Series (FSS'22), Nov 2022, Arlington, United States. 
    \item Anthony Favier, Shashank Shekhar, Rachid Alami. Anticipating False Beliefs and Planning Pertinent Reactions in Human-Aware Task Planning with Models of Theory of Mind. PlanRob Workshop - International Conference on Automated Planning and Scheduling (ICAPS'23), Jul 2023, Prague, Czech Republic. 
    \item Anthony Favier, Shashank Shekhar, Rachid Alami. Models and Algorithms for Human-Aware Task Planning with Integrated Theory of Mind. IEEE International Conference on Robot and Human Interactive Communication (RO-MAN'23), Aug 2023, Busan, South Korea. 
    \item Anthony Favier, Phani Teja Singamaneni, Rachid Alami. Challenging Human-Aware Robot Navigation with an Intelligent Human Simulation System. Social Simulation Conference (SSC'23), Sep 2023, Glasgow, France. 
    \item Anthony Favier, Rachid Alami. Planning Concurrent Actions and Decisions in Human-Robot Joint Action Context. Symbiotic Society with Avatars workshop - ACM/IEEE International Conference on Human-Robot Interaction (HRI'24), Mar 2024, Boulder, United States.

\end{itemize}
    
\subsubsection*{As co-author}
\begin{itemize}
    
    \item Guilhem Buisan, Anthony Favier, Amandine Mayima, Rachid Alami. HATP/EHDA: A Robot Task Planner Anticipating and Eliciting Human Decisions and Actions. IEEE International Conference On Robotics and Automation (ICRA 2022), May 2022, Philadelphia, United States. ⟨10.1109/ICRA46639.2022.9812227⟩. 
    
    \item Phani-Teja Singamaneni, Anthony Favier, Rachid Alami. Towards Benchmarking Human-Aware Social Robot Navigation: A New Perspective and Metrics. IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), 2023, Aug 2023, Busan, South Korea.
    \item Phani-Teja Singamaneni, Anthony Favier, Rachid Alami. Human-Aware Navigation Planner for Diverse Human-Robot Contexts. 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Sep 2021, Prague (online), Czech Republic. 
    \item Phani-Teja Singamaneni, Anthony Favier, Rachid Alami. Invisible Humans in Human-aware Robot Navigation. IEEE International Conference on Robotics and Automation (ICRA 2022), May 2022, Philadelphia, United States.
    \item Phani-Teja Singamaneni, Anthony Favier, Rachid Alami. Watch out! There may be a Human. Addressing Invisible Humans in Social Navigation. 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022), Oct 2022, Kyoto, Japan. 

    \item Olivier Hauterville, Camino Fernández, Phani-Teja Singamaneni, Anthony Favier, Vicente Matellán, et al.. IMHuS: Intelligent Multi-Human Simulator. IROS2022 Workshop: Artificial Intelligence for Social Robots Interacting with Humans in the Real World, Oct 2022, Kyoto, Japan. 
    \item Olivier Hauterville, Camino Fernández, Phani-Teja Singamaneni, Anthony Favier, Vicente Matellán, et al.. Interactive Social Agents Simulation Tool for Designing Choreographies for Human-Robot-Interaction Research. ROBOT2022: Fifth Iberian Robotics Conference, Nov 2022, Zaragoza, Spain. 
\end{itemize}
    
    
    