\chapter*{Introduction}
\addstarredchapter{Introduction}
\markboth{Introduction}{Introduction}

\newcommand{\mysection}[1]{%
    \section*{#1}%
    \addcontentsline{toc}{section}{#1}%
    \markright{#1}%
}


\minitoc

\acrfull{hrc} is a growing field in robotics and \acrfull{ai} research that aims to enable safe and effective teamwork between humans and robots.
This field concerns fully autonomous robots. Hence, it excludes exoskeletons or teleoperated robots such as surgery manipulators or remotely operated (aerial) vehicles. 

The work presented is assumed to be in the Joint Action context, which is described in \cite{sebanz_joint_2006} as ``any form of social interaction whereby two or more individuals coordinate their actions in space and time to bring about a change in the environment''. Various relationships can exist between humans and robots, e.g., collaborators, companions, guides, tutors, or social interaction partners. In all these cases, we think the robot should help and facilitate the human in terms of physical effort, mental workload, and even emotional state.

Industrial robots are already popular in factories because they are fast, accurate, reliable, and never get tired, which makes them ideal for repetitive factory tasks. 
However, such robots are usually in dedicated areas where humans cannot enter for safety reasons. 
Hence, it is still an open challenge to endow robots with enough reliable reasoning capabilities and compliant motion control to allow efficient and trusted direct collaboration between humans and robots. 

Moreover, \acrshort{hrc} can also occur in various contexts that must be considered, ranging from co-worker robots in factories to householder robots for our everyday lives and including service robots in public places like restaurants and shops.

Focused on the decisional aspect of \acrshort{hrc}, this work aims to design autonomous robots able to make explainable, acceptable, and efficient decisions to collaborate with humans. 

\acrfull{hrc} is a multidisciplinary field that opens several technical challenges to address. The ideal collaborative robot should be the aggregation of solutions for each of the challenges listed below:

\begin{itemize}
    \item \textbf{Navigation}: The robot should be able to acceptably and efficiently move in a human-populated environment. This implies being mechanically designed for it, anticipating and planning correct trajectories, and being able to adapt and follow these trajectories in real time. The robot should not move threateningly and should account for humans.

    \item \textbf{Manipulation}: The robot should be able to manipulate objects to interact with its environment. Hence, the robot should have an actuator like an arm and a gripper and should be able to exhibit motions that are efficient and safe to nearby humans.

    \item \textbf{Communication}: To achieve congruent interaction and collaboration, collaborative agents must communicate. This implies that the robot should be able to communicate information to the human and understand the one received from the latter. These communications can be verbal or non-verbal.

    \item \textbf{Perception}: It is mandatory for the robot to have a reliable perception scheme to know the position of near objects, obstacles, and humans. First, relevant sensors must be used and placed on the robot or in the environment itself. After, by reasoning on the sensory data, relevant facts must be extracted about the robot's environment, such as objects' positions, spatial relations, reachable objects, human knowledge, intentions, or the state of the current goal. 
    
    \item \uline{\textbf{Decision-making}}: This aspect is the focus of my work and implies that the robot should be able to make relevant decisions to be collaborative, that is, planning its actions to solve a collaborative task. It also implies being able to supervise the task execution and make online decisions to adapt to uncertainties in real time, which includes human actions and commands. 

\end{itemize}
    
\mysection{Contributions and manuscript organization}

My work addressed the \textbf{decision-making} aspect of \acrshort{hrc} and led to three main contributions summarized below.

I began by participating in the development of a novel human-aware task planner called HATP/EHDA~\cite{buisan_hatpehda_icra}. This approach considers two distinct agent models: an uncontrollable one to estimate the human's behavior and a controllable one to plan the robot's actions accordingly. The agent models include distinct beliefs, agendas, and action models. As a result, the planner can anticipate and even elicit human decisions and actions, but it never compels them. For these reasons, we believe this approach is promising to address HRC, and I built two of my main contributions upon this approach.

My first contribution is to propose some models and algorithms of the Theory of Mind and to integrate them into the deliberation process of HATP/EHDA. Despite considering distinct beliefs, they were only updated according to the description of the action effect provided in the estimated human action model. This means, for instance, that modeling the human observing and learning a new fact by entering a room had to be manually scripted in the `move' action description. With this contribution, we propose that an agent can learn by observing their surroundings or an action execution. Additionally, we propose a way to detect false human beliefs during the planning process, which may be detrimental to the task. Eventually, fix these relevant belief divergences by planning minimal verbal robot communication or delaying robot action that the human will initially not observe.

My second contribution brings planning and execution closer by addressing the turn-taking assumption of HATP/EHDA and exploring parallel executions. We formulated a step-based model of compliant and concurrent joint action. This model describes how the two agents should coordinate as well as four possible online human decisions about the execution: (1) the human decides to be passive and let the robot act alone, (2) the human acts alone and the robot is passive, (3) the human starts acting then the robot adapts and acts in parallel, and finally (4) the human deliberately let the robot decide and start acting before complying with it. This model guides the deliberation process to explore relevant courses of concurrent actions. After exploration, the robot's behavioral policy is extracted using a plan evaluation based on estimations of human preferences. Eventually, by following the produced policy, the robot can comply concurrently with any human online decisions and aims to satisfy human preferences, which can be updated online.

My last contribution is distinguishable from the previous two because it addresses navigation decision-making instead of task planning. Indeed, I designed and implemented two systems simulating interactive social navigating agents endowed with decision-making processes. Additionally, these systems include evaluation processes to record data, compute metrics, and plot navigation performances. Consequently, these systems generate challenging situations that permit challenging, debugging, and evaluating robot navigation schemes in intricate human-populated scenarios. The first system, Intelligent Human Simulator (InHuS), simulates one human agent endowed with complex reasoning processes. The second system, Intelligent Multi Human Simulator (IMHuS), simulates several agents with social group behaviors but with less individual reasoning capabilities. 

These contributions are detailed in the rest of this manuscript, structured as follows.

\textbf{TODO: update structure description with less details since contributions are already described above.}

Chapter~\ref{chap:1} provides more details about the context of my PhD by discussing related fields and works of HRC. This chapter eventually highlights the gap in the literature that motivates my PhD work.

Part~\ref{part:1} gathers all my work concerning task planning for HRC. It represents a major portion of my PhD work and includes the chapters~\ref{chap:2}, \ref{chap:3}, \ref{chap:4}, \ref{chap:5}, and \ref{chap:6}.

Chapter~\ref{chap:2} familiarizes the reader with the HATP/EHDA task planner. Indeed, I participated in its development and this planner has been the keystone of my two contributions to task-planning for HRC. Hence, the reader should understand both this task planner's motivation and methods.

Chapter~\ref{chap:3} introduces my first main contribution which incorporates Theory of Mind concepts in HRC task-planning, more precisely, in the HATP/EHDA planning process.
Some models and algorithms are proposed and evaluated to better estimate human beliefs in order to better anticipate their potential actions. As a result, we can identify when the human has a false belief about a fact evaluated as relevant for the task. In such cases, the robot can proactively inform the human to correct the false belief or the robot can purposely delay its action to make sure the human sees its execution and infer the corresponding fact, avoiding verbal communication. 

In Chapter~\ref{chap:4}, as my second main contribution, I address the lack of concurrent actions of HATP/EHDA to improve fluency in collaboration. Inspired by the Joint Action literature, we designed a model of concurrent and compliant execution for HRC in the form of an automaton. We also propose to evaluate plans based on an estimation of the human inner preferences. A novel task planning approach taking into account the mentioned execution model and plan evaluation is proposed. This approach generates concurrent robot policies compliant with human online decisions and preferences. 

Chapter~\ref{chap:5} is a technical description of an interactive simulator I developed to execute the robot policy generated by the approach described in the previous chapter. This simulator proposes an execution scheme based on the model of execution to run and supervise the robot policy in a 3D simulator. It also allows a human operator to perform actions through intuitive mouse control. Hence, this simulator offers a way to collaborate with a robot following the approach we designed and is used in the next chapter to evaluate the approach.    

Chapter~\ref{chap:6} presents a user study validating the approach proposed in Chapter~\ref{chap:4} using the simulator described in Chapter~\ref{chap:5}. For this purpose, several scenarios have been designed using a BlocksWorld task, and human participants were asked to collaborate with the simulated robot to evaluate its behavior. We compared our approach with a baseline consisting of a robot following a simpler version of the model of execution. 

Conclusions regarding part~\ref{part:1} follow this chapter before starting the second part of this thesis. 

Part~\ref{part:2} concerns decision-making in navigation and how to simulate interactive social navigating agents. Despite not being my main research topic, this subject represents significant work in my PhD. This part includes the two last chapters: \ref{chap:7} and \ref{chap:8}.

Chapter~\ref{chap:7} describes my third contribution in which I address the decision-making challenge in navigation to allow the robot to move in a human-populated environment acceptably and efficiently. I developed a system producing an ``intelligent'' human avatar that, while being reactive, can make rational decisions about navigation tasks. This system serves as a benchmarking and testing tool for robot navigation systems to be challenged. This way, robot navigation systems can be evaluated, tuned, and stress tested in simulation allowing them to run mature real-life experiments faster.  

Chapter~\ref{chap:8} presents an additional work with the same rationales as the approach described in Chapter~\ref{chap:7} and is largely inspired by it. However, this work addresses a major limitation of the previous one which is not being able to simulate several human agents. This other approach can choreograph several agents with group movements and social behaviors. Despite having limited individual decision-making compared to the previous approach, this additional work generates pertinent and challenging intricate situations with several agents which is beneficial to the social robotic research.

Conclusions concerning both Chapter \ref{chap:7} and \ref{chap:8} end part~\ref{part:2}.

Eventually, I share general conclusions regarding all of my PhD work in a dedicated part before providing additional materials in the appendix.  

\mysection{List of Publications}

\subsubsection*{As main author}
\begin{itemize}

    \item Anthony Favier, Phani-Teja Singamaneni, Rachid Alami. Simulating Intelligent Human Agents for Intricate Social Robot Navigation. Social Robot Navigation workshop - Robotics: Science and Systems (RSS'21), Jul 2021, Washington, United States. 
    \item Anthony Favier, Phani-Teja Singamaneni, Rachid Alami. An Intelligent Human Avatar to Debug and Challenge Human-aware Robot Navigation Systems. Late Breaking Report - 2022 ACM/IEEE International Conference on Human-Robot Interaction (HRI'22), Mar 2022, Sapporo, Japan. 
    \item Anthony Favier, Shashank Shekhar, Rachid Alami. Robust Planning for Human-Robot Joint Tasks with Explicit Reasoning on Human Mental State. AI-HRI Symposium at AAAI Fall Symposium Series (FSS'22), Nov 2022, Arlington, United States. 
    \item Anthony Favier, Shashank Shekhar, Rachid Alami. Anticipating False Beliefs and Planning Pertinent Reactions in Human-Aware Task Planning with Models of Theory of Mind. PlanRob Workshop - International Conference on Automated Planning and Scheduling (ICAPS'23), Jul 2023, Prague, Czech Republic. 
    \item Anthony Favier, Shashank Shekhar, Rachid Alami. Models and Algorithms for Human-Aware Task Planning with Integrated Theory of Mind. IEEE International Conference on Robot and Human Interactive Communication (RO-MAN'23), Aug 2023, Busan, South Korea. 
    \item Anthony Favier, Phani Teja Singamaneni, Rachid Alami. Challenging Human-Aware Robot Navigation with an Intelligent Human Simulation System. Social Simulation Conference (SSC'23), Sep 2023, Glasgow, France. 
    \item Anthony Favier, Rachid Alami. Planning Concurrent Actions and Decisions in Human-Robot Joint Action Context. Symbiotic Society with Avatars workshop - ACM/IEEE International Conference on Human-Robot Interaction (HRI'24), Mar 2024, Boulder, United States.

\end{itemize}
    
\subsubsection*{As co-author}
\begin{itemize}
    
    \item Guilhem Buisan, Anthony Favier, Amandine Mayima, Rachid Alami. HATP/EHDA: A Robot Task Planner Anticipating and Eliciting Human Decisions and Actions. IEEE International Conference On Robotics and Automation (ICRA 2022), May 2022, Philadelphia, United States. ⟨10.1109/ICRA46639.2022.9812227⟩. 
    
    \item Phani-Teja Singamaneni, Anthony Favier, Rachid Alami. Towards Benchmarking Human-Aware Social Robot Navigation: A New Perspective and Metrics. IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), 2023, Aug 2023, Busan, South Korea.
    \item Phani-Teja Singamaneni, Anthony Favier, Rachid Alami. Human-Aware Navigation Planner for Diverse Human-Robot Contexts. 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Sep 2021, Prague (online), Czech Republic. 
    \item Phani-Teja Singamaneni, Anthony Favier, Rachid Alami. Invisible Humans in Human-aware Robot Navigation. IEEE International Conference on Robotics and Automation (ICRA 2022), May 2022, Philadelphia, United States.
    \item Phani-Teja Singamaneni, Anthony Favier, Rachid Alami. Watch out! There may be a Human. Addressing Invisible Humans in Social Navigation. 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022), Oct 2022, Kyoto, Japan. 

    \item Olivier Hauterville, Camino Fernández, Phani-Teja Singamaneni, Anthony Favier, Vicente Matellán, et al.. IMHuS: Intelligent Multi-Human Simulator. IROS2022 Workshop: Artificial Intelligence for Social Robots Interacting with Humans in the Real World, Oct 2022, Kyoto, Japan. 
    \item Olivier Hauterville, Camino Fernández, Phani-Teja Singamaneni, Anthony Favier, Vicente Matellán, et al.. Interactive Social Agents Simulation Tool for Designing Choreographies for Human-Robot-Interaction Research. ROBOT2022: Fifth Iberian Robotics Conference, Nov 2022, Zaragoza, Spain. 
\end{itemize}
    
    
    